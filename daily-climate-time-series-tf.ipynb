{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-25T07:52:23.707548Z","iopub.execute_input":"2022-01-25T07:52:23.708061Z","iopub.status.idle":"2022-01-25T07:52:23.738859Z","shell.execute_reply.started":"2022-01-25T07:52:23.707968Z","shell.execute_reply":"2022-01-25T07:52:23.737702Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# import libraries\nimport numpy as np\nimport pandas as pd \nimport tensorflow as tf\nfrom dateutil.parser import parse\ndateparse=lambda dates:parse(dates)\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:52:23.744002Z","iopub.execute_input":"2022-01-25T07:52:23.744232Z","iopub.status.idle":"2022-01-25T07:52:25.405834Z","shell.execute_reply.started":"2022-01-25T07:52:23.744204Z","shell.execute_reply":"2022-01-25T07:52:25.404808Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# load data from csv file and parse dates \ntrain_data = pd.read_csv('../input/daily-climate-time-series-data/DailyDelhiClimateTrain.csv',\n                         parse_dates=['date'],date_parser=dateparse)\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:52:25.407738Z","iopub.execute_input":"2022-01-25T07:52:25.408402Z","iopub.status.idle":"2022-01-25T07:52:25.518547Z","shell.execute_reply.started":"2022-01-25T07:52:25.408331Z","shell.execute_reply":"2022-01-25T07:52:25.517618Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('../input/daily-climate-time-series-data/DailyDelhiClimateTest.csv',\n                         parse_dates=['date'],date_parser=dateparse)\ntest_data","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:52:25.521697Z","iopub.execute_input":"2022-01-25T07:52:25.522059Z","iopub.status.idle":"2022-01-25T07:52:25.549171Z","shell.execute_reply.started":"2022-01-25T07:52:25.522013Z","shell.execute_reply":"2022-01-25T07:52:25.548507Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# check cloumn data types\nprint(train_data.dtypes)\nprint(test_data.dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:52:25.550204Z","iopub.execute_input":"2022-01-25T07:52:25.550861Z","iopub.status.idle":"2022-01-25T07:52:25.557505Z","shell.execute_reply.started":"2022-01-25T07:52:25.550821Z","shell.execute_reply":"2022-01-25T07:52:25.556723Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# convert data and menatemp column into numpy arraies for both test and training dfs\ntrain_series = np.array(train_data.meantemp)\ntrain_time = np.array(train_data.date)\ntest_series = np.array(test_data.meantemp)\ntest_time = np.array(test_data.date)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:52:25.558492Z","iopub.execute_input":"2022-01-25T07:52:25.559437Z","iopub.status.idle":"2022-01-25T07:52:25.727979Z","shell.execute_reply.started":"2022-01-25T07:52:25.559377Z","shell.execute_reply":"2022-01-25T07:52:25.726915Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# print shapes \nprint(train_series.shape)\nprint(test_series.shape)\nprint(train_time.shape)\nprint(test_time.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:52:25.729674Z","iopub.execute_input":"2022-01-25T07:52:25.730252Z","iopub.status.idle":"2022-01-25T07:52:25.742889Z","shell.execute_reply.started":"2022-01-25T07:52:25.730200Z","shell.execute_reply":"2022-01-25T07:52:25.741847Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# plot meantep and date columns \nplt.figure(figsize=(10, 6))\nplt.plot(train_time,train_series)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:52:25.744401Z","iopub.execute_input":"2022-01-25T07:52:25.744816Z","iopub.status.idle":"2022-01-25T07:52:26.045805Z","shell.execute_reply.started":"2022-01-25T07:52:25.744772Z","shell.execute_reply":"2022-01-25T07:52:26.044933Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"window_size = 33 # 33 time steps that will be used as features to predict the next time step in the time series \nbatch_size = 50 # the number of training examples in one forward/backward pass throught the network.\n                # 1000/50 = 20 groups of 50 will be proagated throught the network \nshuffle_buffer_size = 500 # shuffle data so that its not in any order ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:52:26.046928Z","iopub.execute_input":"2022-01-25T07:52:26.047127Z","iopub.status.idle":"2022-01-25T07:52:26.052238Z","shell.execute_reply.started":"2022-01-25T07:52:26.047101Z","shell.execute_reply":"2022-01-25T07:52:26.051422Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# convert dataset into training data that the model can use\n\n# function inputs: data series, size of the window,The size of the batches to use when training,\n# the size of the shuffle buffer, which determines how the data will be shuffled.\n# Expand the dimensions of the series\n# Create dataset ds from the series\n# Slice the data up into the appropriate windows, shifted by one time set.\n# keep them all the same size by setting drop remainder to true.\n# flatten the data into numpy array in the size of our window_size + 1.\n# shuffle data so that its not in order\n# than split data into features and labels  \n\ndef windowed_dataset(series, window_size, batch_size, shuffle_buffer_size):\n    series = tf.expand_dims(series, axis=-1)\n    ds = tf.data.Dataset.from_tensor_slices(series)\n    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n    ds = ds.shuffle(shuffle_buffer_size)\n    ds = ds.map(lambda w: (w[:-1], w[1:]))\n    return ds.batch(batch_size).prefetch(1)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:52:26.053485Z","iopub.execute_input":"2022-01-25T07:52:26.053830Z","iopub.status.idle":"2022-01-25T07:52:26.064892Z","shell.execute_reply.started":"2022-01-25T07:52:26.053798Z","shell.execute_reply":"2022-01-25T07:52:26.063986Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# helper function that can preform forecasting after training model\ndef model_forecast(model, series, window_size):\n    ds = tf.data.Dataset.from_tensor_slices(series)\n    ds = ds.window(window_size, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda w: w.batch(window_size))\n    ds = ds.batch(50).prefetch(1)\n    forecast = model.predict(ds)\n    return forecast","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:52:26.066488Z","iopub.execute_input":"2022-01-25T07:52:26.066750Z","iopub.status.idle":"2022-01-25T07:52:26.077505Z","shell.execute_reply.started":"2022-01-25T07:52:26.066717Z","shell.execute_reply":"2022-01-25T07:52:26.076636Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# used to find the optimum learning rate for the optimizer (form of hyperparameter tuning) using conv1D, LSTM, and dense layer\ntf.keras.backend.clear_session() # this helps avoid clutter from old models and layers\ntf.random.set_seed(51)  # to get reproducable results \nnp.random.seed(51)  # generate pseudo-random numbers \n\ntrain_set = windowed_dataset(train_series, window_size, batch_size, shuffle_buffer_size)\nprint(train_set)\nprint(train_series.shape)\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n                      strides=1, padding=\"causal\",\n                      activation=\"relu\",\n                      input_shape=[None, 1]),\n  tf.keras.layers.LSTM(64, return_sequences=True),\n  tf.keras.layers.LSTM(64, return_sequences=True),\n  tf.keras.layers.Dense(30, activation=\"relu\"),\n  tf.keras.layers.Dense(10, activation=\"relu\"),\n  tf.keras.layers.Dense(1),\n  tf.keras.layers.Lambda(lambda x: x * 100) # scale outputs by 100 using lambda layer \n])\n\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-8 * 10**(epoch / 20)) # to tune the learning rate set up a callback \n\noptimizer = tf.keras.optimizers.SGD(learning_rate=1e-8, momentum=0.9)\nmodel.compile(loss=tf.keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nhistory = model.fit(train_set, epochs=100, callbacks=[lr_schedule])","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:52:26.093694Z","iopub.execute_input":"2022-01-25T07:52:26.094213Z","iopub.status.idle":"2022-01-25T07:56:51.896318Z","shell.execute_reply.started":"2022-01-25T07:52:26.094162Z","shell.execute_reply":"2022-01-25T07:56:51.895551Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# plot the learning rate loss \nplt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\nplt.axis([1e-8, 1e-3, 0, 30])","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:56:51.897532Z","iopub.execute_input":"2022-01-25T07:56:51.897776Z","iopub.status.idle":"2022-01-25T07:56:52.676669Z","shell.execute_reply.started":"2022-01-25T07:56:51.897747Z","shell.execute_reply":"2022-01-25T07:56:52.675669Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# optimum learning rate found was headed towards 1e-4 \ntf.keras.backend.clear_session() # this helps avoid clutter from old models and layers\ntf.random.set_seed(51)\nnp.random.seed(51)\n#batch_size = 16\ndataset = windowed_dataset(train_series, window_size, batch_size, shuffle_buffer_size)\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv1D(filters=32, kernel_size=3,\n                      strides=1, padding=\"causal\",\n                      activation=\"relu\",\n                      input_shape=[None, 1]),\n  tf.keras.layers.LSTM(32, return_sequences=True),\n  tf.keras.layers.LSTM(32, return_sequences=True),\n  tf.keras.layers.Dense(1),\n  tf.keras.layers.Lambda(lambda x: x * 100)\n])\n\noptimizer = tf.keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9)\nmodel.compile(loss=tf.keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nhistory = model.fit(dataset,epochs=100)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T07:56:52.678001Z","iopub.execute_input":"2022-01-25T07:56:52.678233Z","iopub.status.idle":"2022-01-25T08:00:10.929926Z","shell.execute_reply.started":"2022-01-25T07:56:52.678205Z","shell.execute_reply":"2022-01-25T08:00:10.929029Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"window_size = 1\nforecast = model_forecast(model, test_series[..., np.newaxis], window_size)\nforecast = forecast[window_size:-1, -1, 0]\nprint(forecast.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T08:00:10.932583Z","iopub.execute_input":"2022-01-25T08:00:10.934575Z","iopub.status.idle":"2022-01-25T08:00:11.891562Z","shell.execute_reply.started":"2022-01-25T08:00:10.934518Z","shell.execute_reply":"2022-01-25T08:00:11.890622Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.plot(test_time, test_series) #  plot test time and its corrsponding meantep as test_series\nplt.plot(test_time[:112], forecast) #  plot validation time and the predicted meantep \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T08:00:11.892754Z","iopub.execute_input":"2022-01-25T08:00:11.892971Z","iopub.status.idle":"2022-01-25T08:00:12.143329Z","shell.execute_reply.started":"2022-01-25T08:00:11.892943Z","shell.execute_reply":"2022-01-25T08:00:12.142452Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(\"First 10 Predictions :\",\"\\n\", forecast[:7])\nprint('')\nprint('Actual first 10 values:', \"\\n\", test_series[:7])","metadata":{"execution":{"iopub.status.busy":"2022-01-25T08:00:12.144647Z","iopub.execute_input":"2022-01-25T08:00:12.144912Z","iopub.status.idle":"2022-01-25T08:00:12.152594Z","shell.execute_reply.started":"2022-01-25T08:00:12.144880Z","shell.execute_reply":"2022-01-25T08:00:12.151648Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print('Mean absolute error:')\ntf.keras.metrics.mean_absolute_error(test_series[:112], forecast).numpy()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T08:00:12.154004Z","iopub.execute_input":"2022-01-25T08:00:12.154324Z","iopub.status.idle":"2022-01-25T08:00:12.168709Z","shell.execute_reply.started":"2022-01-25T08:00:12.154281Z","shell.execute_reply":"2022-01-25T08:00:12.167949Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# predictions on the left and actual values on the right \nm_p = pd.Series(forecast,test_series[:112])\nm_p","metadata":{"execution":{"iopub.status.busy":"2022-01-25T08:00:12.170044Z","iopub.execute_input":"2022-01-25T08:00:12.170260Z","iopub.status.idle":"2022-01-25T08:00:12.184741Z","shell.execute_reply.started":"2022-01-25T08:00:12.170234Z","shell.execute_reply":"2022-01-25T08:00:12.183603Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}